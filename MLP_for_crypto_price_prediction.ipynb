{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP for crypto price prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhanv/Cypto_RoboAdvisor/blob/main/MLP_for_crypto_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAOdoYlbK2Kf"
      },
      "source": [
        "\n",
        "The central goal is to analyse the cryptomarket and see if a deep learning model can predict the fluctuation of prices in conjunction with sentiment data. To this end, we hope to construct a few models (In this notebook we are exploring with MLP) of varying complexity to help learn the patterns (if any) and help eliminate some of the uncertainty of this market. We believe that crypto currencies would have a prominent position in the future of finance and this paper would shed light into how people view the currency.\n",
        "\n",
        "The simplest model option: a MLP model. Since a MLP model does not have any inbuilt time-series attention mechanism, it is the simplest model that could be used for our task. After experimentation and hypertuning, we decided on using ReLU activation, MSE loss, Adam optimization, and a learning rate of around 3e-5. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA72BL-rBgDj",
        "outputId": "8b85d371-9e72-49ea-9526-65c32742285b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5GlquFNESH0"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZRQjO6_Bo4G",
        "outputId": "908096ac-343e-427e-9e8d-27f48d069561"
      },
      "source": [
        "# imports\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import random\n",
        "import pathlib\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "dev, torch.get_num_threads()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpdgnNubw70a"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VCHeq-bw8he"
      },
      "source": [
        "# @title Helper functions\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.axis(False)\n",
        "    plt.show()\n",
        "\n",
        "def progress(epoch, loss, epochs=100):\n",
        "    return HTML(\"\"\"\n",
        "        <label for=\"file\">Training loss: {loss}</label>\n",
        "        <progress\n",
        "            value='{epoch}'\n",
        "            max='{epochs}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {epoch}\n",
        "        </progress>\n",
        "    \"\"\".format(loss=loss, epoch=epoch, epochs=epochs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wU8xOyNCspz"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r7edThb-amX"
      },
      "source": [
        "def download_data(sentiment):\n",
        "  df = pd.read_csv(\"/content/drive/MyDrive/CIS 522/CIS 522 Final Project/Data/bitcoin_complete.csv\")\n",
        "  df.head()\n",
        "\n",
        "  df['Volume USDT'] = df['Volume USDT'].apply(lambda x : float(\"Nan\") if x == 0 else x)  \n",
        "  df['Volume USDT'] = df['Volume USDT'].interpolate(method = 'linear', limit_direction = 'forward')\n",
        "  if sentiment: \n",
        "    cpt_full_df = df.iloc[:,1:]\n",
        "  else: \n",
        "    cpt_full_df = df.iloc[:,1:7]\n",
        "\n",
        "  return cpt_full_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IzmmHbPD4Fr"
      },
      "source": [
        "## Plotting (Without normalizations)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vps4yFSSD7P-"
      },
      "source": [
        "# fig = plt.figure(figsize=(15,10))\n",
        "# st = fig.suptitle(\"Crypto Close Price and Volume\", fontsize=20)\n",
        "# st.set_y(0.92)\n",
        "\n",
        "# ax1 = fig.add_subplot(211)\n",
        "# ax1.plot(cpt_full_df['close'], label='crypto Close Price')\n",
        "# ax1.set_xticks(range(0, cpt_full_df.shape[0], 200))\n",
        "# ax1.set_xticklabels(cpt_full_df['date'].loc[::200])\n",
        "# ax1.set_ylabel('Close Price', fontsize=18)\n",
        "# ax1.legend(loc=\"upper left\", fontsize=12)\n",
        "\n",
        "# ax2 = fig.add_subplot(212)\n",
        "# ax2.plot(cpt_full_df['Volume USDT'], label='Crypto Volume')\n",
        "# ax2.set_xticks(range(0, cpt_full_df.shape[0], 200))\n",
        "# ax2.set_xticklabels(cpt_full_df['date'].loc[::200])\n",
        "# ax2.set_ylabel('Volume USDT', fontsize=18)\n",
        "# ax2.legend(loc=\"upper left\", fontsize=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNBIMQMhD9xY"
      },
      "source": [
        "## Normalizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3bjUk2Jn278"
      },
      "source": [
        "def percentage_format(cpt_full_df, sentiment):\n",
        "  # Calculate\n",
        "\n",
        "  cpt_full_df[\"open\"] = cpt_full_df[\"open\"].pct_change()\n",
        "  cpt_full_df[\"close\"] = cpt_full_df[\"close\"].pct_change()\n",
        "  cpt_full_df[\"low\"] = cpt_full_df[\"low\"].pct_change()\n",
        "  cpt_full_df[\"high\"] = cpt_full_df[\"high\"].pct_change()\n",
        "  cpt_full_df[\"Volume USDT\"] = cpt_full_df[\"Volume USDT\"].pct_change()\n",
        "\n",
        "  if sentiment: \n",
        "    cpt_full_df[\"reddit_posts\"] = cpt_full_df[\"reddit_posts\"].pct_change()\n",
        "    cpt_full_df[\"reddit_likes_total\"] = cpt_full_df[\"reddit_likes_total\"].pct_change()\n",
        "    cpt_full_df[\"google_trends\"] = cpt_full_df[\"google_trends\"].pct_change()\n",
        "    cpt_full_df[\"twitter_posts\"] = cpt_full_df[\"twitter_posts\"].pct_change()\n",
        "\n",
        "  cpt_full_df.dropna(how=\"any\", axis=0, inplace=True)\n",
        "\n",
        "  return cpt_full_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMsxkqFLHbm1"
      },
      "source": [
        "def difference_format(cpt_full_df, sentiment):\n",
        "  cpt_full_df[\"open\"] = cpt_full_df[\"open\"].diff()\n",
        "  cpt_full_df[\"close\"] = cpt_full_df[\"close\"].diff()\n",
        "  cpt_full_df[\"low\"] = cpt_full_df[\"low\"].diff()\n",
        "  cpt_full_df[\"high\"] = cpt_full_df[\"high\"].diff()\n",
        "  cpt_full_df[\"Volume USDT\"] = cpt_full_df[\"Volume USDT\"].diff()\n",
        "  \n",
        "  if sentiment: \n",
        "    cpt_full_df[\"reddit_posts\"] = cpt_full_df[\"reddit_posts\"].diff()\n",
        "    cpt_full_df[\"reddit_likes_total\"] = cpt_full_df[\"reddit_likes_total\"].diff()\n",
        "    cpt_full_df[\"google_trends\"] = cpt_full_df[\"google_trends\"].diff()\n",
        "    cpt_full_df[\"twitter_posts\"] = cpt_full_df[\"twitter_posts\"].diff()\n",
        "\n",
        "  cpt_full_df.dropna(how=\"any\", axis=0, inplace=True)\n",
        "\n",
        "  return cpt_full_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d53RWgrOEBO0"
      },
      "source": [
        "def normalize(cpt_full_df, sentiment):\n",
        "  min_return = min(cpt_full_df[['open', 'high', 'low', 'close']].min(axis=0))\n",
        "  max_return = max(cpt_full_df[['open', 'high', 'low', 'close']].max(axis=0))\n",
        "\n",
        "  # Min-max normalize price columns (0-1 range)\n",
        "  cpt_full_df['open'] = (cpt_full_df['open'] - min_return) / (max_return - min_return)\n",
        "  cpt_full_df['high'] = (cpt_full_df['high'] - min_return) / (max_return - min_return)\n",
        "  cpt_full_df['low'] = (cpt_full_df['low'] - min_return) / (max_return - min_return)\n",
        "  cpt_full_df['close'] = (cpt_full_df['close'] - min_return) / (max_return - min_return)\n",
        "\n",
        "  min_volume = cpt_full_df['Volume USDT'].min(axis=0)\n",
        "  max_volume = cpt_full_df['Volume USDT'].max(axis=0)\n",
        "\n",
        "  # Min-max normalize volume columns (0-1 range)\n",
        "  cpt_full_df['Volume USDT'] = (cpt_full_df['Volume USDT'] - min_volume) / (max_volume - min_volume)\n",
        "\n",
        "\n",
        "  if sentiment: \n",
        "    # Min max reddit stuff \n",
        "    min_volume = cpt_full_df['reddit_weighted_score'].min(axis=0)\n",
        "    max_volume = cpt_full_df['reddit_weighted_score'].max(axis=0)\n",
        "\n",
        "    cpt_full_df['reddit_weighted_score'] = (cpt_full_df['reddit_weighted_score'] - min_volume) / (max_volume - min_volume)\n",
        "\n",
        "    min_volume = cpt_full_df['reddit_posts'].min(axis=0)\n",
        "    max_volume = cpt_full_df['reddit_posts'].max(axis=0)\n",
        "\n",
        "    cpt_full_df['reddit_posts'] = (cpt_full_df['reddit_posts'] - min_volume) / (max_volume - min_volume)\n",
        "\n",
        "    min_volume = cpt_full_df['reddit_likes_total'].min(axis=0)\n",
        "    max_volume = cpt_full_df['reddit_likes_total'].max(axis=0)\n",
        "\n",
        "    cpt_full_df['reddit_likes_total'] = (cpt_full_df['reddit_likes_total'] - min_volume) / (max_volume - min_volume)\n",
        "\n",
        "    min_volume = cpt_full_df['google_trends'].min(axis=0)\n",
        "    max_volume = cpt_full_df['google_trends'].max(axis=0)\n",
        "\n",
        "    cpt_full_df['google_trends'] = (cpt_full_df['google_trends'] - min_volume) / (max_volume - min_volume)\n",
        "\n",
        "    min_volume = cpt_full_df['twitter_posts'].min(axis=0)\n",
        "    max_volume = cpt_full_df['twitter_posts'].max(axis=0)\n",
        "\n",
        "    cpt_full_df['twitter_posts'] = (cpt_full_df['twitter_posts'] - min_volume) / (max_volume - min_volume)\n",
        "\n",
        "  return cpt_full_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ypZRgsnod7J"
      },
      "source": [
        "def apply_transformations(cpt_full_df, sentiment):\n",
        "  if data_format == 1:\n",
        "    cpt_full_df = percentage_format(cpt_full_df, sentiment)\n",
        "  elif data_format == 2: \n",
        "    cpt_full_df = difference_format(cpt_full_df, sentiment)    \n",
        "  if normalize == 1: \n",
        "    cpt_full_df = normalize(cpt_full_df, sentiment)\n",
        "  return cpt_full_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMHz9nYp78fJ"
      },
      "source": [
        "## Splitting into train, test, and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYMtPtnAEDe6"
      },
      "source": [
        "def split_data(cpt_full_df):\n",
        "  per_of_test = 0.1\n",
        "  per_of_val = 0.1\n",
        "\n",
        "  times = sorted(cpt_full_df.index.values)\n",
        "  last_npct = sorted(cpt_full_df.index.values)[-int(per_of_test*len(times))] # Last 10% of series\n",
        "  last_2npct = sorted(cpt_full_df.index.values)[-int((per_of_val+per_of_test)*len(times))] # Last 20% of series\n",
        "\n",
        "  df_train = cpt_full_df[(cpt_full_df.index < last_2npct)]  # Training data are 80% of total data\n",
        "  df_val = cpt_full_df[(cpt_full_df.index >= last_2npct) & (cpt_full_df.index < last_npct)]\n",
        "  df_test = cpt_full_df[(cpt_full_df.index >= last_npct)]\n",
        "\n",
        "  # Remove date column\n",
        "  df_train.drop(columns=['date'], inplace=True)\n",
        "  df_val.drop(columns=['date'], inplace=True)\n",
        "  df_test.drop(columns=['date'], inplace=True)\n",
        "\n",
        "  closing_index=df_train.columns.get_loc('close')\n",
        "\n",
        "  # Convert pandas columns into arrays\n",
        "  train_data = df_train.values\n",
        "  val_data = df_val.values\n",
        "  test_data = df_test.values\n",
        "  print(f'Training data shape: {train_data.shape}')\n",
        "  print(f'Validation data shape: {val_data.shape}')\n",
        "  print(f'Test data shape: {test_data.shape}')\n",
        "\n",
        "  df_train.head()\n",
        "\n",
        "  return train_data, val_data, test_data, closing_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dX11-HFXRHY"
      },
      "source": [
        "def sequence_data(train_data, val_data, test_data, closing_index):\n",
        "  # Training data\n",
        "  X_train, y_train = [], []\n",
        "  for i in range(seq_len+day_out_pred-1, len(train_data)):\n",
        "    X_train.append(train_data[i-seq_len-day_out_pred+1:i-day_out_pred+1]) # Chunks of training data with a length of 128 df-rows\n",
        "    y_train.append(train_data[:, closing_index][i]) #Value of 4th column (Close Price) of df-row 128+1\n",
        "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "  ###############################################################################\n",
        "\n",
        "  # Validation data\n",
        "  X_val, y_val = [], []\n",
        "  for i in range(seq_len+day_out_pred-1, len(val_data)):\n",
        "      X_val.append(val_data[i-seq_len-day_out_pred+1:i-day_out_pred+1])\n",
        "      y_val.append(val_data[:, closing_index][i])\n",
        "  X_val, y_val = np.array(X_val), np.array(y_val)\n",
        "\n",
        "  ###############################################################################\n",
        "\n",
        "  # Test data\n",
        "  X_test, y_test = [], []\n",
        "  for i in range(seq_len+day_out_pred-1, len(test_data)):\n",
        "      X_test.append(test_data[i-seq_len-day_out_pred+1:i-day_out_pred+1])\n",
        "      y_test.append(test_data[:, closing_index][i])    \n",
        "  X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "  print('Training set shape', X_train.shape, y_train.shape)\n",
        "  print('Validation set shape', X_val.shape, y_val.shape)\n",
        "  print('Testing set shape' ,X_test.shape, y_test.shape)\n",
        "  \n",
        "  return X_train, y_train, X_val, y_val, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycd2DwigCvsl"
      },
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VORKfMKHXZ80"
      },
      "source": [
        "def create_dataloaders(X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "  X_train = torch.FloatTensor(X_train.astype(float)).to(dev)\n",
        "  y_train = torch.FloatTensor(y_train).to(dev)\n",
        "  training_dataset = TensorDataset(X_train, y_train)\n",
        "  train_loader = DataLoader(training_dataset, batch_size=batch_size, drop_last=True,\n",
        "                          shuffle=True)\n",
        "\n",
        "  X_val = torch.FloatTensor(X_val.astype(float)).to(dev)\n",
        "  y_val = torch.FloatTensor(y_val).to(dev)\n",
        "  validation_dataset = TensorDataset(X_val, y_val) \n",
        "  val_loader = DataLoader(validation_dataset, batch_size=batch_size, drop_last=True,\n",
        "                          shuffle=True)\n",
        "\n",
        "  X_test = torch.FloatTensor(X_test.astype(float)).to(dev)\n",
        "  y_test = torch.FloatTensor(y_test).to(dev)\n",
        "  test_dataset = TensorDataset(X_test, y_test) \n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, drop_last=True,\n",
        "                          shuffle=True)\n",
        "  \n",
        "  return train_loader, val_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6JC-b2s_AJR"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, actv, num_inputs, hidden_units, num_outputs):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        exec('self.actv = nn.%s'%actv)   # [TO-DO]\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(hidden_units)):\n",
        "          next_num_inputs = hidden_units[i] \n",
        "          new_layer = nn.Linear(num_inputs, next_num_inputs)\n",
        "          nn.init.xavier_normal_(new_layer.weight)\n",
        "          self.layers += [new_layer]   # [TO-DO]\n",
        "\n",
        "          # exec('actv = nn.%s'%actv)\n",
        "          self.layers += [self.actv]\n",
        "\n",
        "          new_batchnorm = nn.BatchNorm1d(next_num_inputs)\n",
        "          self.layers += [new_batchnorm]\n",
        "\n",
        "          num_inputs = next_num_inputs\n",
        "\n",
        "        self.out = nn.Linear(num_inputs, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # flattening\n",
        "        x = x.view(x.shape[0], -1)   # [TO-DO]\n",
        "\n",
        "        for layer in self.layers:\n",
        "          # x = self.actv(layer(x))  # [TO-DO]\n",
        "          x = layer(x)\n",
        "\n",
        "        x = self.out(x) # [TO-DO]\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7TVLvFHa92c"
      },
      "source": [
        "def train(net, criterion, optimizer,\n",
        "                              train_loader, val_loader, \n",
        "                              num_epochs=1, verbose=True, \n",
        "                              training_plot=False):\n",
        "  if verbose:\n",
        "    progress_bar = display(progress(0, 0, num_epochs), display_id=True)\n",
        "\n",
        "  net.train()\n",
        "  training_losses = []\n",
        "  validation_losses = []\n",
        "  for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "      running_loss = 0.0\n",
        "      running_accuracy = 0.0\n",
        "      total = 0\n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(dev).float()\n",
        "          labels = labels.to(dev).float()\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = net(inputs)\n",
        "\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          total += labels.size(0)\n",
        "\n",
        "          # print statistics\n",
        "          if verbose:\n",
        "          #   training_losses += [loss.item()]\n",
        "          #   running_loss += loss.item()\n",
        "            if i % 10 == 9:    # update every 10 mini-batches\n",
        "                progress_bar.update(progress(epoch+1, running_loss / 10, num_epochs))\n",
        "          #       running_loss = 0.0\n",
        "\n",
        "      training_losses.append(running_loss/len(train_loader))\n",
        "\n",
        "      net.eval()\n",
        "      running_loss = 0.0\n",
        "      total = 0\n",
        "      for data in val_loader:\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(dev).float()\n",
        "          labels = labels.to(dev).float()\n",
        "\n",
        "\n",
        "          outputs = net(inputs)\n",
        "\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          total += labels.size(0)\n",
        "          \n",
        "      validation_losses.append(running_loss/len(val_loader))\n",
        "\n",
        "      print('Training loss: %0.2f %%' % (training_losses[-1]))\n",
        "      print('Validation loss: %0.2f %%' % (validation_losses[-1]))\n",
        "\n",
        "  return training_losses, validation_losses\n",
        "\n",
        "\n",
        "def test(net, data_loader):\n",
        "  net.eval()\n",
        "  MAE_total = 0\n",
        "  MAPE_total = 0\n",
        "  total = 0\n",
        "  for data in data_loader:\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(dev).float()\n",
        "      labels = labels.to(dev).float()\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      MAE_total += (outputs - labels).abs().sum().item()\n",
        "      MAPE_total +=  ((labels - outputs).abs() / labels.abs()).sum().item()\n",
        "      total += labels.size(0)\n",
        "      \n",
        "  MAE = MAE_total / total\n",
        "  MAPE = MAPE_total / total\n",
        "  return MAE, MAPE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rcjjh3IJb0S6"
      },
      "source": [
        "def train_model(X_train, train_loader, val_loader):\n",
        "  net = Net(activation, X_train.shape[1] * X_train.shape[2], architecture, 1).to(dev) \n",
        "  optimizer = optim.Adam(net.parameters(), lr)\n",
        "  training_losses, validation_losses  = train(net, criterion, optimizer,\n",
        "                                        train_loader,val_loader,\n",
        "                                        num_epochs=50)\n",
        "  return net, training_losses, validation_losses "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX_53PjTyqXa"
      },
      "source": [
        "def get_results (net, train_loader, val_loader, test_loader):\n",
        "  train_MAE, train_MAPE = test(net, train_loader)\n",
        "  val_MAE, val_MAPE = test(net, val_loader)\n",
        "  test_MAE, test_MAPE = test(net, test_loader)\n",
        "\n",
        "  return train_MAE, train_MAPE,  val_MAE, val_MAPE,  test_MAE, test_MAPE, "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xWOtK8km8DF"
      },
      "source": [
        "# Displaying and saving results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsy8ztjDswyi"
      },
      "source": [
        "def write_results(train_MAE, train_MAPE,  val_MAE, val_MAPE,  test_MAE, test_MAPE):\n",
        "  file=open(results_folder + \"/results.txt\", \"a+\")\n",
        "  file.write(\"%d : data_format\\n\" % data_format)\n",
        "  file.write(\"%d : day_out_pred\\n\" % day_out_pred)\n",
        "  file.write(\"%d : seq_len\\n\" % seq_len)\n",
        "  file.write(\"%d : normalized\\n\" % normalization)\n",
        "  file.write(\"\\n\")\n",
        "  file.write(\"Train MAE: \" + str(train_MAE) + \", MAPE: \" + str(train_MAPE) + \"\\n\")\n",
        "  file.write(\"Validation MAE: \" + str(val_MAE) + \", MAPE: \" + str(val_MAPE) + \"\\n\")\n",
        "  file.write(\"Test MAE: \" + str(test_MAE) + \", MAPE: \" + str(test_MAPE) + \"\\n\")\n",
        "  file.write(\"\\n\")\n",
        "  file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-bYZru_tpwv"
      },
      "source": [
        "# Loss plot \n",
        "def save_lossplot (training_losses, validation_losses):\n",
        "  plt.title(\"Losses\")\n",
        "  plt.plot(training_losses,label=\"Training loss\")\n",
        "  plt.plot(validation_losses, label = \"Validation loss\")\n",
        "  plt.legend()\n",
        "  plt.xlabel('Batch')\n",
        "  plt.ylabel('Training loss')\n",
        "  file_name = str(data_format) + \" \" + str(day_out_pred) + \" \" + str(seq_len) + \" \" + str(normalization) + \" losses\"\n",
        "  plt.savefig(results_folder + \"/\" + file_name + \".png\")\n",
        "  plt.show()\n",
        "  plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbiwF9XWEv_b"
      },
      "source": [
        "def save_resultplot (net, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "  #Calculate predication for training, validation and test data\n",
        "  train_pred = net(X_train).detach().cpu()\n",
        "  val_pred = net(X_val).detach().cpu()\n",
        "  test_pred = net(X_test).detach().cpu()\n",
        "\n",
        "  '''Display results'''\n",
        "\n",
        "  fig = plt.figure(figsize=(15,20))\n",
        "  st = fig.suptitle(\"MLP model\", fontsize=22)\n",
        "  st.set_y(0.92)\n",
        "\n",
        "  #Plot training data results\n",
        "  ax11 = fig.add_subplot(311)\n",
        "  ax11.plot(y_train, label='Crypto Closing Returns')\n",
        "  ax11.plot(train_pred, label='Predicted Crypto Closing Returns')\n",
        "  # ax11.plot(train_data[:, 3], label='Crypto Closing Returns')\n",
        "  # ax11.plot(np.arange(seq_len, train_pred.shape[0]+seq_len), train_pred, linewidth=3, label='Predicted Crypto Closing Returns')\n",
        "  ax11.set_title(\"Training Data\", fontsize=18)\n",
        "  ax11.set_xlabel('Date')\n",
        "  ax11.set_ylabel('Crypto Closing Returns')\n",
        "  ax11.legend(loc=\"best\", fontsize=12)\n",
        "\n",
        "  #Plot validation data results\n",
        "  ax21 = fig.add_subplot(312)\n",
        "  ax21.plot(y_val, label='Crypto Closing Returns')\n",
        "  ax21.plot(val_pred, label='Predicted Crypto Closing Returns')\n",
        "  # ax21.plot(val_data[:, 3], label='Crypto Closing Returns')\n",
        "  # ax21.plot(np.arange(seq_len, val_pred.shape[0]+seq_len), val_pred, linewidth=3, label='Predicted Crypto Closing Returns')\n",
        "  ax21.set_title(\"Validation Data\", fontsize=18)\n",
        "  ax21.set_xlabel('Date')\n",
        "  ax21.set_ylabel('Crypto Closing Returns')\n",
        "  ax21.legend(loc=\"best\", fontsize=12)\n",
        "\n",
        "  #Plot test data results\n",
        "  ax31 = fig.add_subplot(313)\n",
        "  ax31.plot(y_test, label='Crypto Closing Returns')\n",
        "  ax31.plot(test_pred, label='Predicted Crypto Closing Returns')\n",
        "  # ax31.plot(test_data[:, 3], label='Crypto Closing Returns')\n",
        "  # ax31.plot(np.arange(seq_len, test_pred.shape[0]+seq_len), test_pred, linewidth=3, label='Predicted Crypto Closing Returns')\n",
        "  ax31.set_title(\"Test Data\", fontsize=18)\n",
        "  ax31.set_xlabel('Date')\n",
        "  ax31.set_ylabel('Crypto Closing Returns')\n",
        "  ax31.legend(loc=\"best\", fontsize=12)\n",
        "\n",
        "  file_name = str(data_format) + \" \" + str(day_out_pred) + \" \" + str(seq_len)+ \" \" + str(normalization) + \" results\"\n",
        "  fig.savefig(results_folder + \"/\" + file_name + \".png\")\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDj9d6kTA1yz"
      },
      "source": [
        "# Full process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8uXex-cBAPF"
      },
      "source": [
        "def run_everything (sentiment):\n",
        "  df = download_data(sentiment)\n",
        "  df = apply_transformations(df, sentiment)\n",
        "  train_data, val_data, test_data, closing_index = split_data(df)\n",
        "  X_train, y_train, X_val, y_val, X_test, y_test = sequence_data(train_data, val_data, test_data, closing_index)\n",
        "  train_loader, val_loader, test_loader = create_dataloaders(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "  net, training_losses, validation_losses = train_model(X_train, train_loader, val_loader)\n",
        "  train_MAE, train_MAPE,  val_MAE, val_MAPE,  test_MAE, test_MAPE = get_results(net, train_loader, val_loader, test_loader)\n",
        "  write_results(train_MAE, train_MAPE,  val_MAE, val_MAPE,  test_MAE, test_MAPE)\n",
        "  save_lossplot (training_losses, validation_losses)\n",
        "  X_train = torch.FloatTensor(X_train.astype(float)).to(dev)\n",
        "  X_val = torch.FloatTensor(X_val.astype(float)).to(dev)\n",
        "  X_test = torch.FloatTensor(X_test.astype(float)).to(dev)\n",
        "  save_resultplot (net, X_train, y_train, X_val, y_val, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XWwEh05BArZ"
      },
      "source": [
        "# RUN EVERYTHING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7VBwAD4A6G8"
      },
      "source": [
        "# data_format_values is 0 for percentages, 1 for absolute numbers, 2 for differences\n",
        "data_format_values = [0,1,2]\n",
        "day_out_pred_values = [1,7,14]\n",
        "seq_len_values = [10,20,30]\n",
        "normalization_values = [0,1]\n",
        "\n",
        "batch_size = 12\n",
        "architecture = [50, 30, 10]\n",
        "activation = 'ReLU()'\n",
        "criterion = nn.MSELoss()\n",
        "lr = 3e-5\n",
        "\n",
        "results_folder = \"/content/drive/MyDrive/CIS 522/CIS 522 Final Project/MLP Results no sentiment\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oLKhpvHeA-Yb",
        "outputId": "41d36bea-bb0c-41e7-ef0f-405a8e14ba62"
      },
      "source": [
        "counter = 0\n",
        "for i in range(len(data_format_values)):\n",
        "  for j in range(len(day_out_pred_values)):\n",
        "    for k in range(len(seq_len_values)):\n",
        "      for l in range(len(normalization_values)):\n",
        "        print(\"----------\" + str(counter) + \"-----------\")\n",
        "        data_format = data_format_values[i]\n",
        "        day_out_pred = day_out_pred_values[j]\n",
        "        seq_len = seq_len_values[k]\n",
        "        normalization = normalization_values[l]\n",
        "        run_everything(False)\n",
        "        counter = counter + 1\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape: (1415, 5)\n",
            "Validation data shape: (177, 5)\n",
            "Test data shape: (176, 5)\n",
            "Training set shape (1385, 30, 5) (1385,)\n",
            "Validation set shape (147, 30, 5) (147,)\n",
            "Testing set shape (146, 30, 5) (146,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <label for=\"file\">Training loss: 262305956.875</label>\n",
              "        <progress\n",
              "            value='50'\n",
              "            max='50',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            50\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 23390106.52 %\n",
            "Validation loss: 15591001.83 %\n",
            "Training loss: 23296178.57 %\n",
            "Validation loss: 15566519.58 %\n",
            "Training loss: 23354774.65 %\n",
            "Validation loss: 15619579.42 %\n",
            "Training loss: 23458265.26 %\n",
            "Validation loss: 15556480.75 %\n",
            "Training loss: 23280423.81 %\n",
            "Validation loss: 15528173.50 %\n",
            "Training loss: 23401982.99 %\n",
            "Validation loss: 15449917.67 %\n",
            "Training loss: 23388213.60 %\n",
            "Validation loss: 15290087.08 %\n",
            "Training loss: 23434037.78 %\n",
            "Validation loss: 15317687.75 %\n",
            "Training loss: 23320463.25 %\n",
            "Validation loss: 15300535.00 %\n",
            "Training loss: 23395351.45 %\n",
            "Validation loss: 15482368.83 %\n",
            "Training loss: 23268641.10 %\n",
            "Validation loss: 15397151.08 %\n",
            "Training loss: 23325383.17 %\n",
            "Validation loss: 15403735.92 %\n",
            "Training loss: 23280821.71 %\n",
            "Validation loss: 15429419.00 %\n",
            "Training loss: 23273487.48 %\n",
            "Validation loss: 15472916.92 %\n",
            "Training loss: 23129775.45 %\n",
            "Validation loss: 15488792.33 %\n",
            "Training loss: 23068761.37 %\n",
            "Validation loss: 15499358.17 %\n",
            "Training loss: 22831282.51 %\n",
            "Validation loss: 15160184.50 %\n",
            "Training loss: 22658085.10 %\n",
            "Validation loss: 13882793.50 %\n",
            "Training loss: 22654618.45 %\n",
            "Validation loss: 15204927.50 %\n",
            "Training loss: 22401733.60 %\n",
            "Validation loss: 14565661.00 %\n",
            "Training loss: 22388946.62 %\n",
            "Validation loss: 13704039.58 %\n",
            "Training loss: 22160816.68 %\n",
            "Validation loss: 14369248.67 %\n",
            "Training loss: 22013278.68 %\n",
            "Validation loss: 13200699.92 %\n",
            "Training loss: 21919325.94 %\n",
            "Validation loss: 13812109.00 %\n",
            "Training loss: 21978134.66 %\n",
            "Validation loss: 14155276.88 %\n",
            "Training loss: 21793258.23 %\n",
            "Validation loss: 14586951.67 %\n",
            "Training loss: 21738618.66 %\n",
            "Validation loss: 11942410.00 %\n",
            "Training loss: 21689239.65 %\n",
            "Validation loss: 15168476.71 %\n",
            "Training loss: 21583229.96 %\n",
            "Validation loss: 13346697.42 %\n",
            "Training loss: 21503975.99 %\n",
            "Validation loss: 16665482.75 %\n",
            "Training loss: 21649697.43 %\n",
            "Validation loss: 13134694.38 %\n",
            "Training loss: 21516625.91 %\n",
            "Validation loss: 20027571.25 %\n",
            "Training loss: 21568214.88 %\n",
            "Validation loss: 26685007.79 %\n",
            "Training loss: 21456776.36 %\n",
            "Validation loss: 27965578.04 %\n",
            "Training loss: 21236916.94 %\n",
            "Validation loss: 35159059.58 %\n",
            "Training loss: 21337089.45 %\n",
            "Validation loss: 48993650.33 %\n",
            "Training loss: 21109311.35 %\n",
            "Validation loss: 49528980.46 %\n",
            "Training loss: 21011435.96 %\n",
            "Validation loss: 77428988.58 %\n",
            "Training loss: 21040522.88 %\n",
            "Validation loss: 89544849.04 %\n",
            "Training loss: 20992129.01 %\n",
            "Validation loss: 103014287.08 %\n",
            "Training loss: 20766588.93 %\n",
            "Validation loss: 125412883.71 %\n",
            "Training loss: 20633231.87 %\n",
            "Validation loss: 89495532.17 %\n",
            "Training loss: 20509856.63 %\n",
            "Validation loss: 212123403.79 %\n",
            "Training loss: 20452310.65 %\n",
            "Validation loss: 241686989.12 %\n",
            "Training loss: 20133531.99 %\n",
            "Validation loss: 264215588.08 %\n",
            "Training loss: 20122764.28 %\n",
            "Validation loss: 339021440.12 %\n",
            "Training loss: 20184691.72 %\n",
            "Validation loss: 207553473.46 %\n",
            "Training loss: 20000589.14 %\n",
            "Validation loss: 592481367.25 %\n",
            "Training loss: 19935881.87 %\n",
            "Validation loss: 779168581.67 %\n",
            "Training loss: 23803181.24 %\n",
            "Validation loss: 699520217.38 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}